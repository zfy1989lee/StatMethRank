}
return(d)
}
}
for (j in 1:dmat.col) {
dmat.result$mat[, j] <- dmat.result$mat[, j] +
t(apply(dset1, 1, pair.dist, y=dset2[j, ],
weight=weight, modal=modal))
}
return(dmat.result)
}
Croon
wdmat(Croon, dset1.agg=TRUE, dset2.agg=TRUE)
mwdbm(Croon, 3)
#' Generate all possible permutations of k elements out of n
#'
#' This function generates all permutations of n elements taken k at a time.
#' An efficient way to generate n! permutations of vec
#' in a Lexicographic order without recursive algorithm
#'
#' @param n number of the whole elements
#' @param k number of elements to permute (default the same as n)
#' @param vec the source vector of length n (default as c(1:n))
#' @return a matrix or a vector, each row is a permutation
#' @export
#' @author Li Qinglong <liqinglong0830@@163.com>
#' @examples
#' generate.perms(10, 6)
#' @seealso generate.combn
generate.perms <- function (n, k = n, vec = 1:n)
{
# Generate all possilbe permutations of k elements out of n
# An efficient way to generate n! permutations of vec without recursive
# algorithm in a Lexicographic order
# Author 	: Li Qinglong
# Email 	: liqinglong0830@163.com
# Created   : Oct 29, 2013
if (k > n)
{
stop("k should be smaller than n!")
}
if (length(vec) != n)
{
stop("The vector should contain exactly n elements!")
}
if (n > 1)
{
permns <-function(n, vec = 1:n)
{
# Generate all possible permutaions of vector contains n elements
ans = matrix(1, nrow = factorial(n), ncol = n)
faci = 1
if (n > 1)
{
for (i in 2:n)
{
faci_1 = faci   # i.e. factorail(i-1)
faci = faci_1 * i # i.e. factorial(i)
series = 1:i
head = faci - faci_1 + 1
for (p in i:1)
{
rvec = series[-p]
ans[head:(head + faci_1 - 1), 2:i] =
rvec[ans[1:faci_1, 1:(i-1)]]
head = head - faci_1
}
ans[1:faci, 1] = rep(1:i, each = faci_1)
}
}
ans = matrix(vec[ans], ncol = n)
return(ans)
}
mat = combn(vec, k)
ans = t(apply(mat, 2, permns, n = k))
ans = matrix(ans, ncol = k)
return(ans)
} else return(as.matrix(vec, nrow = 1))
}
mwdbm(Croon, 3)
mwdbm(Croon, 3)
$mea.rank
mean ranks
dim(Croon)
is.matrix(Croon)
load_all()
require(devtools)
require(roxygen)
require(roxygen2)
load_all()
getwd()
getwd()
getwd()
load_all()
wdmat
mvnos.model
data(Sutton)
data(Croon)
Croon
load_all()
load_all()
load_all()
getwd()
Croon
save(Croon, "Croon.rda")
?save
getwd()
load_all()
wdmat
load_all()
wdmat
Croon
data(Croon)
wdmat(Croon, dset1.agg=TRUE, dset2.agg=TRUE)
wdmat(Croon, dset1.agg=TRUE, dset2.agg=TRUE)
getwd（
getwd()
wdmat
rm()
library(DARank)
library(DARank)
mvnos.model
# APA data application
data(APA)
y = freq2case(APA, freq.col = 1)
y = 6 - y
# number of observed judges
n = dim(y)[1]
# number of items
k = dim(y)[2]
# number of parameteros of beta
p = k
beta0 = rep(0, p)
alpha = k + 1
A0 = diag(100, ncol = p, nrow = p)
P = diag(k + 1, ncol = k - 1, nrow = k - 1)
# Construct Z
Z = array(0, dim = c(n, k, p))
for (j in 1:n)
{
Z[j, , ] = diag(1, nrow= k, ncol = p)
}
# Total iterations of Gibbs sampling
MAX_ITERATIONS = 10000
# Number of iterations to be reduced(burnt in)
BURN_IN_ITERATIONS = 1000
output_list = mvnos.model(y, p, Z, beta0, A0, alpha, P,
MAX_ITERATIONS = MAX_ITERATIONS, BURN_IN_ITERATIONS = BURN_IN_ITERATIONS)
library(StatMethRank)
?interaction.test
library(StatMethRank)
?mvnos.model
library(StatMethRank)
?mvnos.model
?StatMethRank-package
?"StatMethRank-package"
remove.package("pmr")
remove.packages("pmr")
install.packages("pmr")
install.packages("pmr")
library(StatMethRank)
library(StatMethRank)
?mvnos.model
library(StatMethRank)
library(StatMethRank)
install.packages("D:/Dropbox/StatMethRank")
install.packages("D:/Dropbox/StatMethRank_1.0")
install.packages("D:/Dropbox/StatMethRank_1.0.zip")
install.packages("D:/Dropbox/StatMethRank_1.0.zip", repos = NULL)
install.packages("D:/Dropbox/StatMethRank_1.0.zip", repos = NULL)
library(StatMethRank)
library(StatMethRank)
install.packages("zoo")
readLines("P:\\上市公司新闻\\报刊文章\\000001\\2002\\06\\06\\25491439.txt")
?readLines
readLines("P:\\上市公司新闻\\报刊文章\\000001\\2002\\06\\06\\25491439.txt", encoding = "UTF-8")
v = readLines("P:\\上市公司新闻\\报刊文章\\000001\\2002\\06\\06\\25491439.txt", encoding = "UTF-8")
Encoding(v)
?fileEncoding
library(StatMethRank)
library(StatMethRank)
data(big4year)
big4year
# example  2.3
library(StatMethRank)
library(pmr)
data(big4year)
big4yr = case2freq(big4year)
rankplot(big4yr)
library(StatMethRank)
case2freq
freq2case
library(StatMethRank)
case2freq
# example  2.3
library(StatMethRank)
library(pmr)
data(big4year)
big4yr = case2freq(big4year)
rankplot(big4yr)
# example 2.6
library(smacof)
data(big4year)
res.rect = smacofRect(big4year, itmax=1000)
plot(res.rect, joint=TRUE, xlim=c(-3,3), asp=1, cex.main=1.5, cex.lab=1.2, cex.axis=1)
plot(res.rect, plot.type = "Shepard", asp=1, cex.main=1.5, cex.lab=1.2, cex.axis=1)
install.packages("smacof")
# example 2.6
library(smacof)
data(big4year)
res.rect = smacofRect(big4year, itmax=1000)
plot(res.rect, joint=TRUE, xlim=c(-3,3), asp=1, cex.main=1.5, cex.lab=1.2, cex.axis=1)
plot(res.rect, plot.type = "Shepard", asp=1, cex.main=1.5, cex.lab=1.2, cex.axis=1)
# example 2.7
library(StatMethRank)
data(big4year)
var.names = colnames(big4year)
big4yr = data.frame(big4year, freq = rep(1, dim(big4year)[1]))
result = mdpref(big4yr, rank.vector = TRUE)
plot(result$item[,1], result$item[,2], asp=1, type = "n",
xlim=c(-1.6, 2.7), main="MDPREF", xlab = "Dimension 1",
ylab = "Dimension 2", cex.main=1.5, cex.lab=1.2,
cex.axis=1)
text(result$item[,1], result$item[,2], labels = var.names,
cex = 0.9, col="blue")
for (i in 1:nrow(big4yr))
{
testx <- c(0,result$ranking[i,6])
testy <- c(0,result$ranking[i,7])
lines(testx, testy, col="red")
}
text(result$ranking[,6],result$ranking[,7], labels=row.names(big4yr), adj=0.5, cex=0.7)
big4year
result
# example 2.7
library(StatMethRank)
data(big4year)
var.names = colnames(big4year)
big4yr = data.frame(big4year, n = rep(1, dim(big4year)[1]))
result = mdpref(big4yr, rank.vector = TRUE)
plot(result$item[,1], result$item[,2], asp=1, type = "n",
xlim=c(-1.6, 2.7), main="MDPREF", xlab = "Dimension 1",
ylab = "Dimension 2", cex.main=1.5, cex.lab=1.2,
cex.axis=1)
text(result$item[,1], result$item[,2], labels = var.names,
cex = 0.9, col="blue")
for (i in 1:nrow(big4yr))
{
testx <- c(0,result$ranking[i,6])
testy <- c(0,result$ranking[i,7])
lines(testx, testy, col="red")
}
text(result$ranking[,6],result$ranking[,7], labels=row.names(big4yr), adj=0.5, cex=0.7)
result
big4yr
freq(APA, freq.col = 1)
freq2case(APA, freq.col = 1)
data(APA)
freq2case(APA, freq.col = 1)
getwd()
tools::showNonASCII( readLines("R/big4year.Rd"))
tools::showNonASCII( readLines("/R/big4year.Rd"))
tools::showNonASCII( readLines("~/R/big4year.Rd"))
tools::showNonASCII( readLines("./R/big4year.Rd"))
tools::showNonASCII( readLines("./man/big4year.Rd"))
read.table("Song.txt")
read.table("Song.txt", header = T)
?read.table
read.table("Song.txt", header = T)
load("D:/Dropbox/StatMethRank/data/Song.rda")
Song
simple_GCT <- function(X, Y, L)
{
tn_sqr = (colMeans(X) - colMeans(Y)) ^ 2 / (apply(X, 2, var) / n + apply(Y, 2, var) / m)
Tn = sum(tn_sqr) / p
# moderate-p version
xi_hat = 1
w_Parzen <- function(x)
{
ifelse(abs(x) < 0.5,
1 - 6 * x^2 + 6 * abs(x^3),
ifelse(abs(x) > 1,
0,
2 * (1 - abs(x))^3
)
)
}
gamma_hat = unlist(lapply(0:(p-1), myfun))
k = (-L + 1):(L - 1)
zeta_hat = sqrt(sum(w_Parzen(k / L) * gamma_hat[abs(k) + 1]))
# finally.....fuck!
return(sqrt(p) * (Tn - xi_hat) / zeta_hat)
}
X = matrix(rnorm(n * p, 0, 1), nrow = n)
Y = matrix(rnorm(m * p, 0, 1), nrow = m)
p = 300
# sample size
# small
n = 45
m = 60
X = matrix(rnorm(n * p, 0, 1), nrow = n)
Y = matrix(rnorm(m * p, 0, 1), nrow = m)
simple_GCT <- function(X, Y, L = 60)
{
tn_sqr = (colMeans(X) - colMeans(Y)) ^ 2 / (apply(X, 2, var) / n + apply(Y, 2, var) / m)
Tn = sum(tn_sqr) / p
# moderate-p version
xi_hat = 1
w_Parzen <- function(x)
{
ifelse(abs(x) < 0.5,
1 - 6 * x^2 + 6 * abs(x^3),
ifelse(abs(x) > 1,
0,
2 * (1 - abs(x))^3
)
)
}
gamma_hat = unlist(lapply(0:(p-1), myfun))
k = (-L + 1):(L - 1)
zeta_hat = sqrt(sum(w_Parzen(k / L) * gamma_hat[abs(k) + 1]))
# finally.....fuck!
return(sqrt(p) * (Tn - xi_hat) / zeta_hat)
}
simple_GCT(X,Y)
simple_GCT <- function(X, Y, L = 60)
{
tn_sqr = (colMeans(X) - colMeans(Y)) ^ 2 / (apply(X, 2, var) / n + apply(Y, 2, var) / m)
Tn = sum(tn_sqr) / p
# moderate-p version
xi_hat = 1
w_Parzen <- function(x)
{
ifelse(abs(x) < 0.5,
1 - 6 * x^2 + 6 * abs(x^3),
ifelse(abs(x) > 1,
0,
2 * (1 - abs(x))^3
)
)
}
myfun <- function(k) # k > 0, lag of autocovariance
{
return (sum((tn_sqr[1:(p - k)] - Tn) * (tn_sqr[(k + 1):p] - Tn)) / (p - k))
}
gamma_hat = unlist(lapply(0:(p-1), myfun))
k = (-L + 1):(L - 1)
zeta_hat = sqrt(sum(w_Parzen(k / L) * gamma_hat[abs(k) + 1]))
# finally.....fuck!
return(sqrt(p) * (Tn - xi_hat) / zeta_hat)
}
simple_GCT(X,Y)
simple_GCT(X,Y)
# NORMAL N(0,1) IND
X = matrix(rnorm(n * p, 0, 1), nrow = n)
Y = matrix(rnorm(m * p, 0, 1), nrow = m)
simple_GCT(X,Y)
cnt = 0
threshold = 0.5
for (times in 1:500)
{
# NORMAL N(0,1) IND
X = matrix(rnorm(n * p, 0, 1), nrow = n)
Y = matrix(rnorm(m * p, 0, 1), nrow = m)
if (simple_GCT(X, Y) > threshold)
cnt = cnt + 1
}
acceptRate = cnt / 500
acceptRate
simple_GCT <- function(X, Y, L = 60)
{
tn_sqr = (colMeans(X) - colMeans(Y)) ^ 2 / (apply(X, 2, var) / n + apply(Y, 2, var) / m)
Tn = sum(tn_sqr) / p
# moderate-p version
xi_hat = 1
w_Parzen <- function(x)
{
ifelse(abs(x) < 0.5,
1 - 6 * x^2 + 6 * abs(x^3),
ifelse(abs(x) > 1,
0,
2 * (1 - abs(x))^3
)
)
}
myfun <- function(k) # k > 0, lag of autocovariance
{
return (sum((tn_sqr[1:(p - k)] - Tn) * (tn_sqr[(k + 1):p] - Tn)) / (p - k))
}
gamma_hat = unlist(lapply(0:(p-1), myfun))
k = (-L + 1):(L - 1)
zeta_hat = sqrt(sum(w_Parzen(k / L) * gamma_hat[abs(k) + 1]))
# finally.....fuck!
return(sqrt(p) * (Tn - xi_hat) / zeta_hat)
}
p = 300
# sample size
# small
n = 45
m = 60
cnt = 0
threshold = 0.5
nSimulationTimes = 500
for (times in 1:nSimulationTimes)
{
# NORMAL N(0,1) IND
X = matrix(rnorm(n * p, 0, 1), nrow = n)
Y = matrix(rnorm(m * p, 0, 1), nrow = m)
if (simple_GCT(X, Y) > threshold)
cntNormal = cntNormal + 1
# Gamma(4, 2) IND, centered at zero
X = matrix(rgamma(n * p, shape = 4, scale = 2), nrow = n)
Y = matrix(rgamma(m * p, shape = 4, scale = 2), nrow = m)
X = X - rowMeans(X)
Y = Y - rowMeans(Y)
if (simple_GCT(X, Y) > threshold)
cntGamma = cntGamma + 1
}
acceptRateNormal = cntNormal / nSimulationTimes
acceptRateGamma = cntGamma / nSimulationTimes
simple_GCT <- function(X, Y, L = 60)
{
tn_sqr = (colMeans(X) - colMeans(Y)) ^ 2 / (apply(X, 2, var) / n + apply(Y, 2, var) / m)
Tn = sum(tn_sqr) / p
# moderate-p version
xi_hat = 1
w_Parzen <- function(x)
{
ifelse(abs(x) < 0.5,
1 - 6 * x^2 + 6 * abs(x^3),
ifelse(abs(x) > 1,
0,
2 * (1 - abs(x))^3
)
)
}
myfun <- function(k) # k > 0, lag of autocovariance
{
return (sum((tn_sqr[1:(p - k)] - Tn) * (tn_sqr[(k + 1):p] - Tn)) / (p - k))
}
gamma_hat = unlist(lapply(0:(p-1), myfun))
k = (-L + 1):(L - 1)
zeta_hat = sqrt(sum(w_Parzen(k / L) * gamma_hat[abs(k) + 1]))
# finally.....fuck!
return(sqrt(p) * (Tn - xi_hat) / zeta_hat)
}
p = 300
# sample size
# small
n = 45
m = 60
cntNormal = 0
cntGamma = 0
threshold = 0.5
nSimulationTimes = 500
for (times in 1:nSimulationTimes)
{
# NORMAL N(0,1) IND
X = matrix(rnorm(n * p, 0, 1), nrow = n)
Y = matrix(rnorm(m * p, 0, 1), nrow = m)
if (simple_GCT(X, Y) > threshold)
cntNormal = cntNormal + 1
# Gamma(4, 2) IND, centered at zero
X = matrix(rgamma(n * p, shape = 4, scale = 2), nrow = n)
Y = matrix(rgamma(m * p, shape = 4, scale = 2), nrow = m)
X = X - rowMeans(X)
Y = Y - rowMeans(Y)
if (simple_GCT(X, Y) > threshold)
cntGamma = cntGamma + 1
}
acceptRateNormal = cntNormal / nSimulationTimes
acceptRateGamma = cntGamma / nSimulationTimes
acceptRateNormal
acceptRateGamma
R.Version()
library(StatMethRank)
data(Croon)
wdmat(Croon, dset1.agg=TRUE, dset2.agg=TRUE)
data(Croon)
mwdbm(Croon, 3)
library(StatMethRank)
Croon
data(Croon)
Croon
library(StatMethRank)
library(StatMethRank)
library(StatMethRank)
library(StatMethRank)
install.packages("devtools")
install.packages("roxygen")
install.packages("roxygen2")
Sys.setlocale(,'CHS')
24/35
library(StatMethRank)
rcpp_hello_world()
rcpp_my_test(1:10,1:10)
library(StatMethRank)
rcpp_hello_world()
library(StatMethRank)
rcpp_hello_world()
generate.perms(3)
generate.perms(4)
rcpp_hello_world()
library(StatMethRank)
rcpp_hello_world()
rcpp_my_test(1:10,1:10)
load(big4year)
load(APA)
data(APA)
cases = freq2case(APA, freq.col = 1)
freqs = case2freq(cases)
freqs
