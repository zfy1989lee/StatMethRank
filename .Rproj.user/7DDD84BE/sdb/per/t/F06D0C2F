{
    "contents" : "#' Multivariate Normal Order-statistics Model.\n#'\n#' Using MCMC methods to fit the MVNOS model. Please install JAGS 3.X (\\url{http://mcmc-jags.sourceforge.net}) and rjags (\\url{http://cran.r-project.org/web/packages/rjags/index.html}) at first.\n#'\n#' @param y \t:an n*k matrix, observed data, each row is an individual's rank of items\n#' @param p \t:number of parameters in MVNOS model\n#' @param Z \t:a n*k*p array of covariates associated with all judges\n#' @param beta0 :a 1*p matrix, prior normal distribution mean parameters\n#' @param A0 \t:a p*p matrix, prior normal distribution variance-covariance matrix\n#' @param alpha :scalar, prior Wishart distribution degree of freedom\n#' @param P \t:a (k-1)*(k-1) matrix, prior Wishart distribution scale matrix\n#' @param BURN_IN_ITERATIONS\t:number of iterations to burn-in at first \n#' @param MAX_ITERATIONS\t:full sample iterations\n#' @param DRAW_CYCLE\t:reduce the full sample by draw-cycle(e.g. draw every 20th draw from the full sample)\n#' @return A list of Gibbs sampling traces\n#' @export\n#' @author Li Qinglong <liqinglong0830@@163.com>\n#' @examples\n#' # APA data application\n#' # It will take about 10 minutes to run the demo.\n#' data(APA)\n#' y = freq2case(APA, freq.col = 1)\n#' y = 6 - y\n#' # number of observed judges\n#' n = dim(y)[1]\n#' # number of items\n#' k = dim(y)[2] \n#' # number of parameteros of beta\n#' p = k \n#' beta0 = rep(0, p)\n#' alpha = k + 1 \n#' A0 = diag(100, ncol = p, nrow = p)\n#' P = diag(k + 1, ncol = k - 1, nrow = k - 1)\n#' # Construct Z\n#' Z = array(0, dim = c(n, k, p))\n#' for (j in 1:n)\n#' {\n#'    Z[j, , ] = diag(1, nrow= k, ncol = p)\n#' }\n#' # Total iterations of Gibbs sampling\n#' MAX_ITERATIONS = 10000\n#' # Number of iterations to be reduced(burnt in)\n#' BURN_IN_ITERATIONS = 1000\n#' # Run the model, time consuming\n#' # output_list = mvnos.model(y, p, Z, beta0, A0, alpha, P, \n#' # MAX_ITERATIONS = MAX_ITERATIONS, BURN_IN_ITERATIONS = BURN_IN_ITERATIONS)\n#' @references Yu, P. L. H. (2000). Bayesian analysis of order-statistics models for ranking data. Psychometrika, 65(3):281-299.\n\nmvnos.model <- function(y, p, Z, beta0 = NULL, A0 = NULL, alpha = NULL, P = NULL, \n\tBURN_IN_ITERATIONS = 1000, MAX_ITERATIONS = 10000, DRAW_CYCLE = 20)\n{\n\t# Author:Li Qinglong\n\t# Input:\n\t# y \t:an n*k matrix, observed data, each row is an individual's rank of items\n\t# p \t:number of parameters in MVNOS model\n\t# Z \t:a n*k*p array of covariates associated with all judges\n\t# beta0 :a 1*p matrix, prior normal distribution mean parameters\n\t# A0 \t:a p*p matrix, prior normal distribution variance-covariance matrix\n\t# alpha :singular, prior Wishart distribution degree of freedom\n\t# P \t:a (k-1)*(k-1) matrix, prior Wishart distribution scale matrix\n\n\t# Output:\n\t# A list of Gibbs sampling trace\n\n\t# \trequire(rjags)\n\t# Initialization\n\t# Prior distribution parameters\n\t# Default ones\n\titem_name = colnames(y)\n\ty = as.matrix(y)\n\tnames(y) = NULL\n\tn = dim(y)[1] # number of individuls\n\tk = dim(y)[2] # number of items\n\tif (is.null(beta0)) beta0 = rep(0, p)\n\t\n\tif (is.null(A0)) A0 = diag(100, ncol = p, nrow = p)\n\tif (any(dim(A0) != c(p, p))) message(\"A0 shouble a p * p matrix.\")\n\t\n\tif (is.null(alpha)) alpha = k + 1 \n\t\n\tif (is.null(P)) P = diag(k + 1, ncol = k - 1, nrow = k - 1)\n\tif (any(dim(P) != c(k - 1, k - 1))) message(\"P shouble a (k-1) * (k-1) matrix.\")\n\n\tX = array(0, dim = c(n, k - 1, p))\n\tfor (j in 1:n)\n\t{\n\t    Zk = Z[j, k,]\n\t    X[j, , ] = t(t(Z[j, 1:(k-1), ]) - Z[j, k, ])\n\t}\n\t\n\t#Starting value of w(Standardized rank score)\n\tyk = matrix(rep(y[, k], k), ncol = k)\t\n\tw = (y - yk) / sqrt((k ^ 2 - 1) / 12)\n\n\t##################################################################\n\t# Start to using JAGS\n\t# Total iterates of Gibbs sampling\n\tMAX_ITERATIONS = MAX_ITERATIONS\n\t# Number of iterates to be reduced(burnt in)\n\tBURN_IN_ITERATIONS = BURN_IN_ITERATIONS\n\tdata <- list(X = X, y = y, n = n, p = p, k = k, alpha = alpha, beta0 = beta0, A0 = A0, P = P)\n\tinit <- list(w = w)\n\tinit$w[, k] = NA\n\n\t# JAGS code\n\t# When p=1, beta ~ dnorm(beta0, A0)\n\tif (p == 1) \n\t{\n\t\tstrModelCode = \"\n\t\tvar X[n, k - 1, p], bounds[n, k - 1, 2], beta[p]\n\n\t\tdata\n\t\t{\n\t\t\tfor(i in 1:n)\n\t\t\t{\n\t\t\t\tfor(j in 1:(k-1))\n\t\t\t\t{\n\t\t\t\t\tones[i, j] <- 1\n\t\t\t\t}\n\t\t\t}\n\t\t\tlower <- -1e+5\n\t\t\tupper <-  1e+5\n\t\t}\n\n\t\tmodel\n\t\t{\n\t\t\tfor (i in 1:n)\n\t\t\t{\n\t\t\t\tfor (j in 1:(k-1))\n\t\t\t\t{\n\t\t\t\t\tbounds[i, j, 1] <- equals(y[i,j], 1) * lower + inprod(w[i, ], equals(y[i, ], y[i, j] - 1))\n\t\t\t\t\tbounds[i, j, 2] <- equals(y[i,j], k) * upper + inprod(w[i, ], equals(y[i, ], y[i, j] + 1))\n\t\t         \tones[i, j] ~ dinterval(w[i, j], bounds[i, j, ])\n\t\t        }\n\t\t        w[i, 1:(k-1)] ~ dmnorm(X[i, , ] * beta, G)\n\t\t      \tw[i, k] <- 0\n\t\t\t}\n\t\t\tbeta ~ dnorm(beta0, A0)\n\t\t   \tG ~ dwish(P, alpha)\n\t\t\tSigma <- inverse(G)\n\t\t}\" \n\t} else\n\t{\n\t\tstrModelCode = \"\n\t\tvar X[n, k - 1, p], bounds[n, k - 1, 2], beta[p]\n\n\t\tdata\n\t\t{\n\t\t\tfor(i in 1:n)\n\t\t\t{\n\t\t\t\tfor(j in 1:(k-1))\n\t\t\t\t{\n\t\t\t\t\tones[i, j] <- 1\n\t\t\t\t}\n\t\t\t}\n\t\t\tlower <- -1e+5\n\t\t\tupper <-  1e+5\n\t\t}\n\n\t\tmodel\n\t\t{\n\t\t\tfor (i in 1:n)\n\t\t\t{\n\t\t\t\tfor (j in 1:(k-1))\n\t\t\t\t{\n\t\t\t\t\tbounds[i, j, 1] <- equals(y[i,j], 1) * lower + inprod(w[i, ], equals(y[i, ], y[i, j] - 1))\n\t\t\t\t\tbounds[i, j, 2] <- equals(y[i,j], k) * upper + inprod(w[i, ], equals(y[i, ], y[i, j] + 1))\n\t\t         \tones[i, j] ~ dinterval(w[i, j], bounds[i, j, ])\n\t\t        }\n\t\t        w[i, 1:(k-1)] ~ dmnorm(X[i, , ] %*% beta, G)\n\t\t      \tw[i, k] <- 0\n\t\t\t}\n\t\t\tbeta ~ dmnorm(beta0, A0)\n\t\t   \tG ~ dwish(P, alpha)\n\t\t\tSigma <- inverse(G)\n\t\t}\"\n\t}\n\tjags <- jags.model(textConnection(strModelCode), data, init)\n\tupdate(jags, BURN_IN_ITERATIONS)\n\tsamp <- coda.samples(jags, c(\"beta\", \"Sigma\"), MAX_ITERATIONS)\n\t# End of running JAGS\n\t#################################################################\n\n\tposterior_data = as.matrix(samp)\n\tdraw_index = seq(DRAW_CYCLE, MAX_ITERATIONS, DRAW_CYCLE)\n\tposterior_trace = posterior_data[draw_index, ]\n\n\tSigma_trace = posterior_trace[, 1:(k-1)^2]\n\tbeta_trace = posterior_trace[, ((k - 1)^2 + 1):((k - 1)^2 + p)]\n\t# Scaled by Sigma11\n\tSigma11 = Sigma_trace[, 1]\n\tbeta_trace = as.matrix(beta_trace / sqrt(Sigma11))\n\tSigma_trace = Sigma_trace / Sigma11\n\t# Create an output list\n\toutput_list = summary.trace(beta_trace, Sigma_trace,  item_name = item_name)\n\treturn(output_list)\n}",
    "created" : 1402374605657.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2376330632",
    "id" : "F06D0C2F",
    "lastKnownWriteTime" : 1402572541,
    "path" : "D:/Dropbox/StatMethRank/R/mvnos.model.R",
    "project_path" : "R/mvnos.model.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}